{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #% matplotlib inline\n",
    "from art import tprint\n",
    "from sklearn import svm \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import pylab\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split # для манипулирования данными\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns \n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #% matplotlib inline\n",
    "from art import tprint\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "url =\"C:\\\\Users\\\\Admin\\\\Desktop\\\\datases\\\\UMAP\\\\soybean-large.data\"  # hone pc\n",
    "url_2= \"C:\\\\Users\\\\Admin\\\\Desktop\\\\datases\\\\UMAP\\\\soybean-large.names\"  # hone pc\n",
    "\n",
    "\n",
    "# url =\"C:\\\\Users\\\\Дмитрий\\\\Desktop\\\\datasets\\\\bob\\\\soybean-large.data\"  # laptop\n",
    "# url_2= \"C:\\\\Users\\\\Дмитрий\\\\Desktop\\\\datasets\\\\bob\\\\soybean-large.names\"  # laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_func(df):\n",
    "    scaler = MinMaxScaler()\n",
    "# X= scaler.fit_transform(y_pred_SVM)\n",
    "\n",
    "    embed = TSNE(\n",
    "        n_components=2, # значение по умолчанию=2. Размерность вложенного пространства.\n",
    "        perplexity=20, # значение по умолчанию=30.0. Перплексия связана с количеством ближайших соседей, которое используется в других алгоритмах обучения на множествах.\n",
    "        early_exaggeration=12, # значение по умолчанию=12.0. Определяет, насколько плотными будут естественные кластеры исходного пространстве во вложенном пространстве и сколько места будет между ними. \n",
    "        learning_rate=200, # значение по умолчанию=200.0. Скорость обучения для t-SNE обычно находится в диапазоне [10.0, 1000.0]. Если скорость обучения слишком высока, данные могут выглядеть как \"шар\", в котором любая точка приблизительно равноудалена от ближайших соседей. Если скорость обучения слишком низкая, большинство точек могут быть похожими на сжатое плотное облако с незначительным количеством разбросов. \n",
    "        n_iter=5000, # значение по умолчанию=1000. Максимальное количество итераций для оптимизации. Должно быть не менее 250.\n",
    "        n_iter_without_progress=300, # значение по умолчанию=300. Максимальное количество итераций без прогресса перед прекращением оптимизации, используется после 250 начальных итераций с ранним преувеличением.\n",
    "        min_grad_norm=0.0000001, # значение по умолчанию=1e-7. Если норма градиента ниже этого порога, оптимизация будет остановлена.\n",
    "        metric='euclidean', # значение по умолчанию='euclidean', Метрика, используемая при расчете расстояния между экземплярами в массиве признаков.\n",
    "        init='random',# {'random', 'pca'} или ndarray формы (n_samples, n_components), значение по умолчанию='random'. Инициализация вложения.\n",
    "        verbose=0, # значение по умолчанию=0. Уровень детализации.\n",
    "        random_state=42, # экземпляр RandomState или None, по умолчанию=None. Определяет генератор случайных чисел. Передача int для воспроизводимых результатов при многократном вызове функции.\n",
    "        method='barnes_hut', # значение по умолчанию='barnes_hut'. По умолчанию алгоритм вычисления градиента использует аппроксимацию Барнса-Хата, работающую в течение времени O(NlogN). метод='exact' будет работать по более медленному, но точному алгоритму за время O(N^2). Следует использовать точный алгоритм, когда количество ошибок ближайших соседей должно быть ниже 3%.\n",
    "        angle=0.5, # значение по умолчанию=0.5. Используется только если метод='barnes_hut' Это компромисс между скоростью и точностью в случае T-SNE с применением алгоритма Барнса-Хата.\n",
    "        n_jobs=-1, # значение по умолчанию=None. Количество параллельных заданий для поиска соседей. -1 означает использование всех процессоров.\n",
    "            )\n",
    "\n",
    "    # Преобразование X\n",
    "    X_embedded = embed.fit_transform(df.reshape(-1, 1))\n",
    "    return X_embedded\n",
    "\n",
    "def umap_function(df, method='MinMax'):\n",
    "\n",
    "    # if method=='MinMax':\n",
    "    #     scaler = MinMaxScaler()\n",
    "    # elif method=='Standard':\n",
    "    #     scaler = preprocessing.StandardScaler()\n",
    "    # else:\n",
    "    #     scaler = preprocessing.RobustScaler()\n",
    "    \n",
    "    # X= scaler.fit_transform(df.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "    manifold = umap.UMAP()#.fit(X)\n",
    "    X_reduced = manifold.fit_transform(df.reshape(-1, 1))\n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaves\n",
      "Counter({'4': 9, '1': 5, '5': 5, '3': 4, '6': 3, '0': 2, '2': 2})\n"
     ]
    }
   ],
   "source": [
    "col_names = [   \"class\",\"date\", \"plant-stand\", \"precip\", \"temp\", \"hail\", \"crop-hist\", \"area-damaged\", \"severity\", \"seed-tmt\", \"germination\", \"plant-growth\", \n",
    "                \"leaves\",\"leafspots-halo\", \"leafspots-marg\", \"leafspot-size\", \"leaf-shread\", \"leaf-malf\", \"leaf-mild\", \"stem\", \"lodging\", \"stem-cankers\",\n",
    "                \"canker-lesion\", \"fruiting-bodies\", \"external decay\", \"mycelium\", \"int-discolor\", \"sclerotia\", \"fruit-pods\", \"fruit spots\", \"seed\",\n",
    "                \"mold-growth\", \"seed-discolor\", \"seed-size\", \"shriveling\", \"roots\"\n",
    "            ]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Read data from URL\n",
    "bob = pd.read_csv(url, names=col_names)\n",
    "color=list(bob)\n",
    "bob=bob.replace(\"?\",0)\n",
    "bob=bob.dropna()\n",
    "\n",
    "for i in list(bob):\n",
    "    try:\n",
    "        bob[i]=bob[i].str.strip() \n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "list_class=bob['class'].to_list()\n",
    "dict_class={}\n",
    "a=1\n",
    "for i in list_class:\n",
    " \n",
    "    if i not in dict_class.keys():\n",
    "        dict_class[i]=a\n",
    "        a+=1\n",
    "# bob=bob.fillna(0)\n",
    "bob=bob.dropna()\n",
    "bob['class']=bob['class'].apply(lambda x: dict_class[x] )  \n",
    "bob=bob.dropna()\n",
    "bob= bob[ (bob['class']== 6) |(bob['class']== 11) |(bob['class']== 7) | (bob['class']==10 ) |(bob['class']== 9) |(bob['class']== 3) ] # (bob['class']==2 ) |\n",
    "\n",
    "predictors, target =bob[color[1:]], bob['class'] #  делим на то что есть и на то что предсказать \n",
    "\n",
    "x_train , x_test , y_train, y_test = train_test_split(predictors['date'], target, random_state=100, test_size = 0.5) # 1А разбить выборку на тренировочную и тестовую \n",
    "X, y = train_test_split(bob, random_state=100)\n",
    "x_test=x_test.values.reshape(-1, 1)\n",
    "\n",
    "print(Counter(x_train)) # узнать сколько классов \n",
    "\n",
    "# y_train=y_train[y_train[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictors, target =bob[color[1:]], bob['class'] #  делим на то что есть и на то что предсказать \n",
    "x_train , x_test , y_train, y_test = train_test_split(predictors, target, random_state=0) # 1А разбить выборку на тренировочную и тестовую \n",
    "X, y = train_test_split(bob, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10,  3,  6,  9, 11,  7, 10, 11,  6, 11,  7,  6,  3,  9,  6, 11,\n",
       "        7, 11,  3,  6,  7,  9,  6, 10, 10, 11,  9,  3,  6, 10,  7,  3,  7,\n",
       "        9,  7,  6,  3,  9, 11,  3,  3, 11, 10, 10,  7,  9,  9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.values.reshape(-1, 1)\n",
    "y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# x_train=x_train.to_frame()\n",
    "sm = SMOTE( k_neighbors = 2, random_state = 100) \n",
    "X_diver_res, y_diver_res = sm.fit_resample(x_train, y_train.ravel())  # из массива массивов делает одномерный массив (ravel)\n",
    "sm = BorderlineSMOTE( k_neighbors = 2,random_state=100, kind='borderline-1')\n",
    "X_res, y_res = sm.fit_resample(x_train, y_train.ravel())\n",
    "\n",
    "sm = BorderlineSMOTE( k_neighbors = 2,random_state=100, kind='borderline-1')\n",
    "X_res_2, y_res_2 = sm.fit_resample(x_train, y_train.ravel()) # .values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1680, 48]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\VS_code\\magic\\MagiCtr\\Интеллектуальные системы и технологии\\pr4\\pr4.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/VS_code/magic/MagiCtr/%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8/pr4/pr4.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m clf_2_SVC \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/VS_code/magic/MagiCtr/%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8/pr4/pr4.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m clf_3_SVC \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/VS_code/magic/MagiCtr/%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8/pr4/pr4.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m clf_predict\u001b[39m=\u001b[39mclf_1_SVC\u001b[39m.\u001b[39;49mfit(x_new_train,y_new_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/VS_code/magic/MagiCtr/%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8/pr4/pr4.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m clf_predict_2\u001b[39m=\u001b[39mclf_2_SVC\u001b[39m.\u001b[39mfit(x_new_train,y_new_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/VS_code/magic/MagiCtr/%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%20%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B%20%D0%B8%20%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8/pr4/pr4.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m clf_predict_3\u001b[39m=\u001b[39mclf_3_SVC\u001b[39m.\u001b[39mfit(x_new_train,y_new_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[0;32m    193\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    194\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    195\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:1164\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1680, 48]"
     ]
    }
   ],
   "source": [
    "for x_new_train,y_new_train, version in zip([x_train, X_diver_res, X_res, X_res_2],[y_train, y_diver_res, y_res, y_res_2], ['ДЕФОЛТ','SMOTE','borderline-SMOTE ','borderline-SMOTE _2']): \n",
    "    try:\n",
    "        x_new_train=x_new_train.values.reshape(-1, 1)\n",
    "    except:\n",
    "        ...\n",
    "\n",
    "    params={'kernel':['linear','rbf' ,  'poly', 'sigmoid'], 'C': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]}\n",
    "\n",
    "    clf_1_SVC = svm.SVC(kernel='linear')\n",
    "    clf_2_SVC = svm.SVC(kernel='rbf') \n",
    "    clf_3_SVC = svm.SVC(kernel='poly')\n",
    "    clf_predict=clf_1_SVC.fit(x_new_train,y_new_train)\n",
    "    clf_predict_2=clf_2_SVC.fit(x_new_train,y_new_train)\n",
    "    clf_predict_3=clf_3_SVC.fit(x_new_train,y_new_train)\n",
    "    clf_SVC = svm.SVC()\n",
    "    y_pred_SVM= clf_predict.predict(x_test)\n",
    "    y_pred_SVM_2= clf_predict_2.predict(x_test)\n",
    "    y_pred_SVM_3= clf_predict_3.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, algorithm='auto')\n",
    "    knn_2 = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "    knn_3 = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "    knn_model = knn.fit(x_new_train,y_new_train)\n",
    "    knn_model_2 = knn_2.fit(x_new_train,y_new_train)\n",
    "    knn_model_3 = knn_3.fit(x_new_train,y_new_train)\n",
    "    y_pred_KNN = knn.predict(x_test)\n",
    "    y_pred_KNN_2 = knn_2.predict(x_test)\n",
    "    y_pred_KNN_3 = knn_3.predict(x_test)\n",
    "    params={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "    grid_search= GridSearchCV(estimator=knn, param_grid=params)\n",
    "    grid_search.fit(x_new_train,y_new_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    random_forest = RandomForestClassifier(n_estimators=100 , criterion='gini')\n",
    "    random_forest_2 = RandomForestClassifier(n_estimators=100, criterion='entropy' )\n",
    "    random_forest_3 = RandomForestClassifier(n_estimators=100 , criterion='log_loss')\n",
    "    random_forest.fit(x_new_train,y_new_train)\n",
    "    random_forest_2.fit(x_new_train,y_new_train)\n",
    "    random_forest_3.fit(x_new_train,y_new_train)\n",
    "    y_pred_RF = random_forest.predict(x_test)\n",
    "    y_pred_RF_2 = random_forest_2.predict(x_test)\n",
    "    y_pred_RF_3 = random_forest_3.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "    params= {'criterion':['gini', 'entropy', 'log_loss'] }\n",
    "    grid_search= GridSearchCV(estimator=random_forest, param_grid=params)\n",
    "    grid_search.fit(x_new_train,y_new_train)\n",
    "\n",
    "\n",
    "\n",
    "    metrics = []\n",
    "    models =  ['SVM' , 'KNN', 'Random_Forest']\n",
    "    predictions=[y_pred_SVM, y_pred_KNN, y_pred_RF]\n",
    "    tprint(version)\n",
    "    for lab,i in zip(models, predictions):\n",
    "        precision, recall, fscore, _ = score(y_test, i, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, i)\n",
    "\n",
    "        \n",
    "        metrics.append(pd.Series({  'precision':precision,  # Точность \n",
    "                                    'recall':recall, # полнота  \n",
    "                                    'fscore':fscore,\n",
    "                                    'accuracy':accuracy,}, name=lab))\n",
    "\n",
    "    metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-мера является хорошим кандидатом на формальную метрику оценки качества классификатора. Она сводит к одному числу две других основополагающих метрики: точность и полноту. Имея в своем распоряжении подобный механизм оценки вам будет гораздо проще принять решение о том являются ли изменения в алгоритме в лучшую сторону или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2637dd3e970>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.scatter(X_diver_res.reshape(1, -1)[0,:] ,y_diver_res , c=[i for i in y_diver_res], s=50, cmap='autumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.        , 4.        , 1.        , 6.        , 1.        ,\n",
       "       4.        , 0.        , 4.        , 5.        , 1.        ,\n",
       "       5.        , 2.        , 2.        , 3.        , 4.        ,\n",
       "       5.        , 4.        , 4.        , 6.        , 3.        ,\n",
       "       3.        , 5.        , 5.        , 4.        , 6.        ,\n",
       "       4.        , 4.        , 0.        , 1.        , 1.        ,\n",
       "       1.        , 4.        , 4.        , 4.85139516, 4.        ,\n",
       "       4.        ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_diver_res.reshape(1, -1)[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10,  6,  6,  3,  9,  3,  7, 10,  7,  7,  3,  6,  9, 11, 11, 11,\n",
       "        6, 11,  3,  9,  9,  6, 10,  6,  7,  9,  3,  7,  3,  7, 10, 10, 10,\n",
       "       11, 11], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_diver_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'kernel':['linear','rbf' ,  'poly', 'sigmoid'], 'C': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]}\n",
    "\n",
    "\n",
    "clf_1_SVC = svm.SVC(kernel='linear')\n",
    "clf_2_SVC = svm.SVC(kernel='rbf') \n",
    "clf_3_SVC = svm.SVC(kernel='poly')\n",
    "clf_predict=clf_1_SVC.fit(x_train,y_train)\n",
    "clf_predict_2=clf_2_SVC.fit(x_train,y_train)\n",
    "clf_predict_3=clf_3_SVC.fit(x_train,y_train)\n",
    "\n",
    "clf_SVC = svm.SVC()\n",
    "y_pred_SVM= clf_predict.predict(x_test)\n",
    "y_pred_SVM_2= clf_predict_2.predict(x_test)\n",
    "y_pred_SVM_3= clf_predict_3.predict(x_test)\n",
    "\n",
    "# grid_search= GridSearchCV(estimator=clf_SVC, param_grid=params)\n",
    "# grid_search.fit(x_train,y_train)\n",
    "# grid_search\n",
    "# print(str(grid_search.best_score_))\n",
    "# print(str(grid_search.best_estimator_))\n",
    "\n",
    "# y_pred_SVM= grid_search.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, algorithm='auto')\n",
    "knn_2 = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "knn_3 = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "\n",
    "knn_model = knn.fit(x_train, y_train)\n",
    "knn_model_2 = knn_2.fit(x_train, y_train)\n",
    "knn_model_3 = knn_3.fit(x_train, y_train)\n",
    "\n",
    "y_pred_KNN = knn.predict(x_test)\n",
    "y_pred_KNN_2 = knn_2.predict(x_test)\n",
    "y_pred_KNN_3 = knn_3.predict(x_test)\n",
    "\n",
    "\n",
    "params={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "grid_search= GridSearchCV(estimator=knn, param_grid=params)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(str(grid_search.best_score_))\n",
    "print(str(grid_search.best_estimator_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100 , criterion='gini')\n",
    "random_forest_2 = RandomForestClassifier(n_estimators=100, criterion='entropy' )\n",
    "random_forest_3 = RandomForestClassifier(n_estimators=100 , criterion='log_loss')\n",
    "random_forest.fit(x_train, y_train)\n",
    "random_forest_2.fit(x_train, y_train)\n",
    "random_forest_3.fit(x_train, y_train)\n",
    "y_pred_RF = random_forest.predict(x_test)\n",
    "y_pred_RF_2 = random_forest_2.predict(x_test)\n",
    "y_pred_RF_3 = random_forest_3.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "params= {'criterion':['gini', 'entropy', 'log_loss'] }\n",
    "grid_search= GridSearchCV(estimator=random_forest, param_grid=params)\n",
    "grid_search.fit(x_train,y_train)\n",
    "print(str(grid_search.best_score_))\n",
    "print(str(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n##################Последнее задание ######################\\n')\n",
    "metrics = []\n",
    "models =  ['SVM' , 'KNN', 'Random_Forest']\n",
    "predictions=[y_pred_SVM, y_pred_KNN, y_pred_RF]\n",
    "\n",
    "for lab,i in zip(models, predictions):\n",
    "    precision, recall, fscore, _ = score(y_test, i, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, i)\n",
    "\n",
    "    \n",
    "    metrics.append(pd.Series({  'precision':precision, \n",
    "                                'recall':recall,\n",
    "                                'fscore':fscore,\n",
    "                                'accuracy':accuracy,}, name=lab))\n",
    "\n",
    "metrics = pd.concat(metrics, axis=1)\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_df1=pd.DataFrame(tsne_func(y_pred_SVM), columns=['x1','x2']) # y_pred_SVM_2\n",
    "x_df2=pd.DataFrame(tsne_func(y_pred_SVM_2), columns=['x1','x2']) \n",
    "x_df3=pd.DataFrame(tsne_func(y_pred_SVM_3), columns=['x1','x2']) \n",
    "tprint(\"TSNE   SVM\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('SVM linear')\n",
    "ax2.set_title('SVM rbf')\n",
    "ax3.set_title('SVM poly')\n",
    "\n",
    "sns.kdeplot(x_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(x_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(x_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(x_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(x_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(x_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_df1=pd.DataFrame(tsne_func(y_pred_KNN), columns=['x1','x2']) # y_pred_SVM_2\n",
    "y_df2=pd.DataFrame(tsne_func(y_pred_KNN_2), columns=['x1','x2']) \n",
    "y_df3=pd.DataFrame(tsne_func(y_pred_KNN_3), columns=['x1','x2']) \n",
    "tprint(\"TSNE   KNN\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('KNN auto') #'auto', 'ball_tree', 'kd_tree',\n",
    "ax2.set_title('KNN rbf')\n",
    "ax3.set_title('KNN ball_tree')\n",
    "\n",
    "sns.kdeplot(y_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(y_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(y_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(y_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(y_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(y_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "z_df1=pd.DataFrame(tsne_func(y_pred_RF), columns=['x1','x2']) # y_pred_SVM_2\n",
    "z_df2=pd.DataFrame(tsne_func(y_pred_RF_3), columns=['x1','x2']) \n",
    "z_df3=pd.DataFrame(tsne_func(y_pred_RF_3), columns=['x1','x2']) \n",
    "tprint(\"TSNE   RandomForest\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('RandomForest gini') # 'gini', 'entropy', 'log_loss'\n",
    "ax2.set_title('RandomForest entropy')\n",
    "ax3.set_title('RandomForest log_loss')\n",
    "\n",
    "sns.kdeplot(z_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(z_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(z_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(z_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(z_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(z_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_df1=pd.DataFrame(umap_function(y_pred_SVM), columns=['x1','x2']) # y_pred_SVM_2\n",
    "x_df2=pd.DataFrame(umap_function(y_pred_SVM_2), columns=['x1','x2']) \n",
    "x_df3=pd.DataFrame(umap_function(y_pred_SVM_3), columns=['x1','x2']) \n",
    "tprint(\"UMAP   SVM\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('SVM linear')\n",
    "ax2.set_title('SVM rbf')\n",
    "ax3.set_title('SVM poly')\n",
    "\n",
    "sns.kdeplot(x_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(x_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(x_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(x_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(x_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(x_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_df1=pd.DataFrame(umap_function(y_pred_KNN), columns=['x1','x2']) # y_pred_SVM_2\n",
    "y_df2=pd.DataFrame(umap_function(y_pred_KNN_2), columns=['x1','x2']) \n",
    "y_df3=pd.DataFrame(umap_function(y_pred_KNN_3), columns=['x1','x2']) \n",
    "tprint(\"UMAP   KNN\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('KNN auto') #'auto', 'ball_tree', 'kd_tree',\n",
    "ax2.set_title('KNN rbf')\n",
    "ax3.set_title('KNN ball_tree')\n",
    "\n",
    "sns.kdeplot(y_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(y_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(y_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(y_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(y_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(y_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "z_df1=pd.DataFrame(umap_function(y_pred_RF), columns=['x1','x2']) # y_pred_SVM_2\n",
    "z_df2=pd.DataFrame(umap_function(y_pred_RF_3), columns=['x1','x2']) \n",
    "z_df3=pd.DataFrame(umap_function(y_pred_RF_3), columns=['x1','x2']) \n",
    "tprint(\"UMAP   RandomForest\")\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols = 3, figsize =(25, 5)) #linear rbf poly\n",
    "ax1.set_title('RandomForest gini') # 'gini', 'entropy', 'log_loss'\n",
    "ax2.set_title('RandomForest entropy')\n",
    "ax3.set_title('RandomForest log_loss')\n",
    "\n",
    "sns.kdeplot(z_df1['x1'], ax = ax1, color ='black')\n",
    "sns.kdeplot(z_df1['x2'], ax = ax1, color ='red')\n",
    "\n",
    "sns.kdeplot(z_df2['x1'], ax = ax2, color ='black')\n",
    "sns.kdeplot(z_df2['x2'], ax = ax2, color ='red')\n",
    "\n",
    "sns.kdeplot(z_df3['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(z_df3['x2'], ax = ax3, color ='red')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
